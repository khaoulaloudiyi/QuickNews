{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "PresseAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaoulaloudiyi/QuickNews/blob/master/PresseAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHdpHSWd_VcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "89f4f87f-c4fc-4b57-f92b-a902b6fa955c"
      },
      "source": [
        "!pip install dateparser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.6/dist-packages (0.7.6)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.6/dist-packages (from dateparser) (2019.12.20)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from dateparser) (2018.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from dateparser) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from dateparser) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->dateparser) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cuLXKie_f42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "66f6ecd0-e387-41f2-b488-2c54225d67a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vun791UC_F-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92a42202-1126-415d-e170-56e0e60a48a2"
      },
      "source": [
        "cd /content/drive/My Drive//MediaInsights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MediaInsights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMJcyVGeINXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9d02442-9b56-4b3c-ab18-3cb1fb3526c7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MediaInsights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwHQAk6z_AIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import csv\n",
        "import dateparser\n",
        "from textblob import TextBlob\n",
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "from collections import Counter \n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stop_words\n",
        "import spacy \n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import nltk \n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q79e_GQyQ-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "67e8cda6-c842-455a-c2e3-7d22065add77"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "swa = stopwords.words('arabic')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kolBwjDQ_AIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cette partie doit être executer une seule fois pour créer le header des deux fichiers csv\n",
        "\n",
        "#Ce fichier joue un rôle principal pour la mise à jour puisqu'il contient le champ lastDate qui réfère à la date ou la dernière mise à jour a été effectué et le champ maxid pour faciliter la recherche du plus grand Id \n",
        "with open('presse_lastUpdate.csv','w',encoding=\"utf-8\") as csv_file:\n",
        "    fieldnames=['country', 'Publication', 'maxId', 'lastDate']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    \n",
        "#Ce fichier est réservé pour stocker les différents articles récupéré grâce au scraping \n",
        "with open('ArticlesAR.csv','w',encoding=\"utf-8\") as csv_file:\n",
        "    fieldnames=['Id','Title','Author','Date','Publication','URL','Content','Language','Country', \"sentiment\", \"Summary\"]\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ppz8Td_AI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#D'abord il faut comprendre la structure des sites web de la presse, chaque presse possède un archive où tous les articles sont stocké, sous forme d'une dizaine d'articles dans plusieurs pages, \n",
        "#chaque page de ce dernier contient plusieurs articles référencé par des liens, et tous ces articles possède le même format et contient l'ensemble des informations sauf \n",
        "#l'information sur le \"sentiment\"\n",
        "\n",
        "#Le principe du Scraping qu'on a utilisé est le suivant \"exemple avec Hespress Ar mais la même chose se répète avec les autres presses\":\n",
        "#d'abord on effectue une étude pour comprendre la structure d'une page de l'archive (code html) afin de récupérer les liens des articles seulement\n",
        "#apres on analyse la structure d'un de ces articles (html) , On parcour l'ensemble des pages de l'archive grâce à la fonction \"add_newArticles_hespres\" cette\n",
        "#fonction utilise la variable p qui représente le numéro de page de l'archive a scrapé, on scrape cette page puis on collecte les liens\n",
        "#href des articles et pour chaque lien on scrape l'article avec la fonction \"scrap_article_Hespress\" et on l'ajout à la dataset Articles\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CebU3ZYcyblW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizing sentences into words\n",
        "def tokenizer(s):\n",
        "    tokens = []\n",
        "    for word in s.split(' '):\n",
        "        tokens.append(word.strip().lower()) #strip remove spaces at the beginning and at the end of the string\n",
        "    return tokens\n",
        "\n",
        "#tokenizing document into sentences \n",
        "def sent_tokenizer(s):\n",
        "    sents = []\n",
        "    for sent in s.split('.'):\n",
        "        sents.append(sent.strip())\n",
        "    return sents\n",
        "\n",
        "def count_words(tokens):\n",
        "    word_counts = {}\n",
        "    for token in tokens:\n",
        "        if token not in stop_words and token not in STOP_WORDS and token not in swa and token not in punctuation:\n",
        "            if token not in word_counts.keys():\n",
        "                word_counts[token] = 1\n",
        "            else:\n",
        "                word_counts[token] += 1\n",
        "    return word_counts\n",
        "\n",
        "def word_freq_distribution(word_counts):\n",
        "    freq_dist = {}\n",
        "    max_freq = max(word_counts.values())\n",
        "    for word in word_counts.keys():  \n",
        "        freq_dist[word] = (word_counts[word]/max_freq)\n",
        "    return freq_dist\n",
        "\n",
        "def score_sentences(sents, freq_dist, max_len=40):\n",
        "    sent_scores = {}  \n",
        "    for sent in sents:\n",
        "        words = sent.split(' ')\n",
        "        for word in words:\n",
        "            if word.lower() in freq_dist.keys():\n",
        "                if len(words) < max_len:\n",
        "                    if sent not in sent_scores.keys():\n",
        "                        sent_scores[sent] = freq_dist[word.lower()]\n",
        "                    else:\n",
        "                        sent_scores[sent] += freq_dist[word.lower()]\n",
        "    return sent_scores\n",
        "\n",
        "def summarize(sent_scores, k):\n",
        "    top_sents = Counter(sent_scores) \n",
        "    summary = ''\n",
        "    scores = []\n",
        "    \n",
        "    top = top_sents.most_common(k)\n",
        "    for t in top: \n",
        "        summary += t[0].strip()+'. '\n",
        "        scores.append((t[1], t[0]))\n",
        "    return summary[:-1], scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX1cymRQ_AI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hespress\n",
        "def scrap_article_Hespress(site, date_max, Id, writer):\n",
        "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
        "    req = Request(site,headers=hdr)\n",
        "    page = urlopen(req)\n",
        "    soup = BeautifulSoup(page)\n",
        "    #Pour les pages ou il n y a pas de titre on ne la traîte pas\n",
        "    if not soup.select('h1.page_title'):\n",
        "        return True, date_max, Id\n",
        "    #pour Obtenir le titre\n",
        "    title = soup.select('h1.page_title')[0].text.strip()\n",
        "    \n",
        "    #Le contenu est stocké dans la div ou l id = \"article_holder\" dans plusieurs paragraphes (balises p) \n",
        "    content_a = soup.findAll(\"div\", {\"id\": \"article_holder\"})\n",
        "    content = ''\n",
        "    for x in content_a:\n",
        "        for c in x.findAll('p'):\n",
        "            #on stocke la totalite du contenu dans la variable contenu\n",
        "            content += c.text + \"\\n\"\n",
        "\n",
        "    scrap_author=soup.findAll(\"span\",{\"class\":\"story_author\"})\n",
        "    longueur=len(scrap_author)\n",
        "    txt=scrap_author[longueur-1].text\n",
        "    var_author = txt.split('-')\n",
        "    #cette partie adapté a la structure des auteurs de hespress\n",
        "    if len(var_author)==1:\n",
        "        author=var_author[0]\n",
        "    else:\n",
        "        author=var_author[1]    \n",
        "    \n",
        "    #la date de l article\n",
        "    date_article=soup.find(\"span\",{\"class\":\"story_date\"}).text\n",
        "    #on regle les problemes de la langue arabe par respecter les normes\n",
        "    date_pub = date_article.replace(\"يوليوز\",\"يوليو\")\n",
        "    date_pub = date_pub.replace(\"غشت\",\"اغسطس\")\n",
        "    date_pub = date_pub.replace(\"نونبر\",\"نوفمبر\")\n",
        "    date_pub = date_pub.replace(\"شتنبر\",\"سبتمبر\")\n",
        "    date_pub = date_pub.replace(\"دجنبر\",\"ديسمبر\")\n",
        "    date_pub = date_pub.replace(\"ماي\",\"مايو\")\n",
        "\n",
        "    \n",
        "    date_publication =  dateparser.parse(date_pub)\n",
        "    language='Ar'\n",
        "    country='Morocco'\n",
        "    publication='Hespress'\n",
        "    #si la date est inferieur a date_max qui correspand a la date ou la dernier mis a jour est effectué on arrête le scraping \n",
        "    if(date_publication <= date_max):\n",
        "        return False, date_publication, Id \n",
        "    Id = Id +1\n",
        "    \n",
        "    #analyse de sentiment \"notre propre proposition\"\n",
        "    en_blob = TextBlob(str(content))\n",
        "    sent = en_blob.sentiment.polarity\n",
        "    if sent <-0.05 :\n",
        "        sentiment = \"Negative\"\n",
        "    elif sent > -0.05 and sent < 0.05 :\n",
        "        sentiment = \"Neutre\"\n",
        "    else :\n",
        "        sentiment = \"Positive\"\n",
        "    #Summarinzing\n",
        "    tokens = tokenizer(content)\n",
        "    sents = sent_tokenizer(content)\n",
        "    word_counts = count_words(tokens)\n",
        "    freq_dist = word_freq_distribution(word_counts)\n",
        "    sent_scores = score_sentences(sents, freq_dist)\n",
        "    summary, summary_sent_scores = summarize(sent_scores, 3)\n",
        "\n",
        "    #on l'ecrit dans le fichier csv \n",
        "    writer.writerow({'Id': Id,'Title': title,'Author': author,'Date':date_publication,'Publication': publication,'URL': site,'Content': content,'Language': language,'Country': country, 'sentiment':sentiment, 'Summary':summary})\n",
        "    return True, date_publication, Id\n",
        "\n",
        "def add_newArticles_hespress(Id, date_max): \n",
        "    #variable pour parcourir les pages de l'archive\n",
        "    p =1\n",
        "    stay = True\n",
        "    fieldnames=['Id','Title','Author','Date', 'Publication','URL','Content','Language','Country','sentiment','Summary']\n",
        "    #Ovrir le fichier Articles une seule fois\n",
        "    with open('ArticlesAR.csv','a+',encoding=\"utf-8\") as csv_file:\n",
        "        article_writer = csv.writer(csv_file)\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        lastDate= date_max\n",
        "        while stay: \n",
        "            site= \"https://www.hespress.com/24-heures/index.\"+str(p)+\".html\"\n",
        "            p = p+1\n",
        "            hdr = {'User-Agent': 'Mozilla/5.0'}\n",
        "            req = Request(site,headers=hdr)\n",
        "            page = urlopen(req)\n",
        "            soup = BeautifulSoup(page)\n",
        "            \n",
        "            #Chercher tous les liens \n",
        "            links = soup.findAll(\"a\")\n",
        "            i=0\n",
        "            for link in links:\n",
        "                if \"#box_most_popular\" == link[\"href\"] :\n",
        "                    break\n",
        "                if 'index.1.html' not in link[\"href\"] and 'https' not in link[\"href\"] and 'http' not in link[\"href\"]: \n",
        "                    if i%3 == 0 :\n",
        "                        #Effectuer le scrapping d'un artcile mais puisque il est repete 3 fois on le utilise la variable i pour \n",
        "                        #ne pas le duppliquer\n",
        "                        stay, date, Id = scrap_article_Hespress('https://www.hespress.com'+link[\"href\"], date_max, Id, writer)\n",
        "                        if date > lastDate:\n",
        "                            #Obtenir la date la plus recente\n",
        "                            lastDate = date\n",
        "                        if not stay :\n",
        "                            break\n",
        "                    i = i+1\n",
        "            if i == 0 :\n",
        "                break\n",
        "    return Id,lastDate\n",
        "\n",
        "def update_hespress():\n",
        "    fieldnames=['country', 'Publication', 'maxId', 'lastDate']\n",
        "    #id_max et lastdate represent les informations les plus importants pour la mise a jour \n",
        "    with open('presse_lastUpdate.csv', newline='') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        readData = [row for row in reader]\n",
        "        found = False\n",
        "        #l'initialisation des 2 variables sert a faire marcher le code meme si c'est la premier fois\n",
        "        id_max = 0 \n",
        "        lastdate = datetime(1 ,1 ,1 , 1, 1)\n",
        "        for row in readData:\n",
        "            if id_max < int(row['maxId']):\n",
        "                id_max = int(row['maxId'])\n",
        "            if row['country'] == \"Morocco\" and row['Publication'] == \"Hespress\" :\n",
        "                lastdate = pd.to_datetime(row['lastDate'])  \n",
        "                found = True\n",
        "        \n",
        "        #Effectuer la collection des données\n",
        "        id_max, lastdate = add_newArticles_hespress(id_max, lastdate)\n",
        "    \n",
        "    #stocké les nouveaux variables id_max et lastdate\n",
        "    if found :\n",
        "        with open('presse_lastUpdate.csv', \"w\", newline='') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            for row in readData:\n",
        "                if row['country'] == \"Morocco\" and row['Publication'] == \"Hespress\" :\n",
        "                    row['maxId'] = id_max\n",
        "                    row['lastDate'] = lastdate\n",
        "                    break\n",
        "            writer.writerows(readData)\n",
        "    if not found:\n",
        "        with open('presse_lastUpdate.csv', \"a+\", newline='') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "            writer.writerow({'country' :'Morocco', 'Publication' : 'Hespress',  'maxId' : id_max, 'lastDate' :lastdate})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "H3_j6-B4_AJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "6790a08f-8cfd-472c-accd-f7345a3ab592"
      },
      "source": [
        "def update():\n",
        "    #update_hespressFR()\n",
        "    #update_LeMatin()\n",
        "    update_hespress()\n",
        "    #updates_TheAtlantic()\n",
        "    #updates_ELMundo()\n",
        "update()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-64332ffe96ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#updates_TheAtlantic()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#updates_ELMundo()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-64332ffe96ac>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#update_hespressFR()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#update_LeMatin()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mupdate_hespress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#updates_TheAtlantic()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#updates_ELMundo()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-175bdc4b7e06>\u001b[0m in \u001b[0;36mupdate_hespress\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m#Effectuer la collection des données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mid_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_newArticles_hespress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m#stocké les nouveaux variables id_max et lastdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-175bdc4b7e06>\u001b[0m in \u001b[0;36madd_newArticles_hespress\u001b[0;34m(Id, date_max)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0;31m#Effectuer le scrapping d'un artcile mais puisque il est repete 3 fois on le utilise la variable i pour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0;31m#ne pas le duppliquer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                         \u001b[0mstay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrap_article_Hespress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.hespress.com'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlastDate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                             \u001b[0;31m#Obtenir la date la plus recente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-175bdc4b7e06>\u001b[0m in \u001b[0;36mscrap_article_Hespress\u001b[0;34m(site, date_max, Id, writer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Mozilla/5.0'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Pour les pages ou il n y a pas de titre on ne la traîte pas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1368\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDY_hOez_AJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}